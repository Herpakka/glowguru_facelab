# %%
# import libraries

# 1. to handle the data
import pandas as pd
import numpy as np

# to visualize the dataset
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.graph_objects as go

# this is for jupyter notebook to show the plot in the notebook itself instead of opening a new window
%matplotlib inline

# To preprocess the data
from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler

# machine learning
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
#Model
import lightgbm as lgb
from catboost import CatBoostClassifier, Pool
from catboost.utils import eval_metric

#Evaluation
from sklearn.metrics import roc_auc_score

# ignore warnings   
import warnings
warnings.filterwarnings('ignore')

# %%
import os
df_train = pd.read_csv('C:/Users/ThongKoon_pro2/Documents/2_66/bigpro/faceLab/Oil/svm/LGBM1_train.csv')

# %%
pd.set_option('display.max_columns', None) 

# %%
df_train.head()

# %%
# Checking the number of rows and columns

num_train_rows, num_train_columns = df_train.shape

# Null Values in Train 
train_null = df_train.isnull().sum().sum()

print("Training Data:")
print(f"Number of Rows: {num_train_rows}")
print(f"Number of Columns: {num_train_columns}\n")


print(f'Null Count in Train: {train_null}')

# %%
# Count duplicate rows in train_data
train_duplicates = df_train.duplicated().sum()


# Print the results
print(f"Number of duplicate rows in train_data: {train_duplicates}")

# %%
# Checking the number of rows and columns
num_train_rows, num_train_columns = df_train.shape

print("Training Data:")
print(f"Number of Rows: {num_train_rows}")
print(f"Number of Columns: {num_train_columns}\n")

# %%
df_train.info()

# %%
df_train.describe()

# %%
col=df_train.columns.tolist()
col

# %%
object_col=[]
for i in range(len(df_train.columns)):
    if df_train[col[i]].dtype=='object':
        object_col.append(col[i])
object_col

# %%
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import lightgbm as lgb
import pandas as pd

# %%
col_to_keep = [
 'GLCM_contrast',
 'GLCM_dissimilarity',
 'GLCM_homogeneity',
 'GLCM_energy',
 'GLCM_correlation',
 'fore_area',
 'fore_oil_all',
 'fore_oil_max',
 'fore_count',
 'fore_dense',
 'fore_spread',
 'fore_avg',
 'fore_oil_maxP',
 'fore_oil_allP',
 'chk_area',
 'chk_oil_all',
 'chk_oil_max',
 'chk_count',
 'chk_dense',
 'chk_spread',
 'chk_avg',
 'chk_oil_maxP',
 'chk_oil_allP',
 'PZfore_area',
 'PZfore_oil_all',
 'PZfore_oil_max',
 'PZfore_count',
 'PZfore_dense',
 'PZfore_spread',
 'PZfore_avg',
 'PZfore_oil_maxP',
 'PZfore_oil_allP',
 'PZchk_area',
 'PZchk_oil_all',
 'PZchk_oil_max',
 'PZchk_count',
 'PZchk_dense',
 'PZchk_spread',
 'PZchk_avg',
 'PZchk_oil_maxP',
 'PZchk_oil_allP']

# %%
X=df_train[col_to_keep]
y=df_train['true_class']
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# %%
# LightGBM classifier with default parameters
lgb_classifier = lgb.LGBMClassifier()
lgb_classifier.fit(X_train, y_train)

# %%
y_pred=lgb_classifier.predict(X_test)

# %%
zero_count=[]
cnt_0=0
cnt_1=0

for i in y_pred:
    if i==0:
        cnt_0=cnt_0+1
    elif i==1:
        cnt_1=cnt_1+1
    
print(cnt_0*100/len(y_test))
print(cnt_1*100/len(y_test))

# %%
from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_curve, roc_auc_score, classification_report

# %%
# Make predictions on the test set
y_pred = lgb_classifier.predict(X_test)
y_prob = lgb_classifier.predict_proba(X_test)[:, 1]

# %%
plt.plot(y_prob)

# %%
# Compute precision, recall, and accuracy
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
accuracy = accuracy_score(y_test, y_pred)

print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'Accuracy: {accuracy:.4f}')
print("___"*27)
print("Classi6ication report", classification_report(y_test, y_pred))

# %%
from sklearn.model_selection import RandomizedSearchCV
import lightgbm as lgb
from scipy.stats import randint as sp_randint

# %%
# Create the classifier
clf = lgb.LGBMClassifier()

# Define the hyperparameter grid
param_dist = {
    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],
    'n_estimators': sp_randint(50, 500),
    'num_leaves': sp_randint(6, 50),
    'max_depth': sp_randint(3, 15),
    'min_child_samples': sp_randint(10, 100),
    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],
    'reg_alpha': [0, 0.1, 0.5, 1, 10],
    'reg_lambda': [0, 0.1, 0.5, 1, 10]
}

# %%
# Run the random search
n_iter_search = 100
random_search = RandomizedSearchCV(clf, param_distributions=param_dist,
                                   n_iter=n_iter_search, cv=5)



random_search.fit(X_train, y_train)



# %%
# Print the best parameters and score
print("Best parameters found: ", random_search.best_params_)
print("Best score: ", random_search.best_score_)

# %%
# Train the classifier with the best parameters
best_clf = lgb.LGBMClassifier(**random_search.best_params_)
best_clf.fit(X_train, y_train)

# %%
# Make predictions on new data
y_pred = best_clf.predict(X_test)

# Evaluate the performance of the model
accuracy = best_clf.score(X_test, y_test)
print("Accuracy: ", accuracy)
print("Classi6ication report", classification_report(y_test, y_pred))

len(col_to_keep)

# %%
test=pd.read_csv('C:/Users/ThongKoon_pro2/Documents/2_66/bigpro/faceLab/Oil/svm/LGBM1_test.csv')
test_data=test[col_to_keep]
test_data.shape

# %%
test_data.head()

# %%
predicted_class = best_clf.predict(test_data)
test.columns

# %%
from sklearn.metrics import confusion_matrix
out1 = test['filename'].apply(lambda x: x.split('/')[1])
out2 = out1.apply(lambda x: x.split('\\')[0])

result = []
for val in out2:
    if val == 'dry':
        result.append(0)
    elif val == 'normal':
        result.append(1)
    elif val == 'oily':
        result.append(2)
out3 = result

result = []
for v1, v2 in zip(out3, predicted_class):
    if v1 == v2:
        result.append(1)
    else:
        result.append(0)
result
mean_result = sum(result)/len(result)

data = {'filename': test['filename'], 'true_class': out3, 'predict': predicted_class, 'corrected': result, f'{mean_result}': ''}


submission = pd.DataFrame(data=data)
submission

# # Assuming y_test contains the true labels and predicted_class contains the predicted labels
# y_test = test['true_class']  # Replace with your actual true labels
# predicted_class = test['true_class']  # Replace with your actual predicted labels

# # Compute the confusion matrix
# cm = confusion_matrix(y_test, predicted_class)

# # Create a DataFrame for better visualization
# cm_df = pd.DataFrame(cm, index=[i for i in range(len(cm))], columns=[i for i in range(len(cm))])

# # Plot the confusion matrix
# plt.figure(figsize=(10, 7))
# sns.heatmap(cm_df, annot=True, fmt='g')
# plt.xlabel('Predicted')
# plt.ylabel('True')
# plt.title('Confusion Matrix')
# plt.show()

# %%
submission.to_csv('submission.csv', index=False)


